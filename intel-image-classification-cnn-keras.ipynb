{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intel Image Classification (CNN - Keras)\n",
    "\n",
    "Hello, I hope you are having a great day.\n",
    "\n",
    "In this notebook, I will try the process of implementing CNN with Keras in order to classify images.\n",
    "1. Firstly, we'll import usefull packages.\n",
    "1. Then, we'll load the data, before visualize and preprocess it.\n",
    "1. We'll try a simple CNN model and then we will evaluate its performances.\n",
    "1. We will then use pre trained model to address this challenge aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-23T06:01:05.478803Z",
     "iopub.status.busy": "2023-04-23T06:01:05.478507Z",
     "iopub.status.idle": "2023-04-23T06:01:07.436918Z",
     "shell.execute_reply": "2023-04-23T06:01:07.436005Z",
     "shell.execute_reply.started": "2023-04-23T06:01:05.478749Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19392\\3002772960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf                \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (556306433.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Modi\\AppData\\Local\\Temp\\ipykernel_19392\\556306433.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install opencv-python\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T06:01:07.438782Z",
     "iopub.status.busy": "2023-04-23T06:01:07.438275Z",
     "iopub.status.idle": "2023-04-23T06:01:07.446986Z",
     "shell.execute_reply": "2023-04-23T06:01:07.446075Z",
     "shell.execute_reply.started": "2023-04-23T06:01:07.438680Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (150, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "We have to write a load_data function that load the images and the labels from the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T06:01:07.449211Z",
     "iopub.status.busy": "2023-04-23T06:01:07.448574Z",
     "iopub.status.idle": "2023-04-23T06:01:07.457341Z",
     "shell.execute_reply": "2023-04-23T06:01:07.456476Z",
     "shell.execute_reply.started": "2023-04-23T06:01:07.449022Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "        Load the data:\n",
    "            - 14,034 images to train the network.\n",
    "            - 3,000 images to evaluate how accurately the network learned to classify images.\n",
    "    \"\"\"\n",
    "    \n",
    "    datasets = ['../input/seg_train/seg_train', '../input/seg_test/seg_test']\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE) \n",
    "                \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')   \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T06:01:07.459521Z",
     "iopub.status.busy": "2023-04-23T06:01:07.459020Z"
    }
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's explore the dataset\n",
    "We can ask ourselves:\n",
    "* How many training and testing examples do we have ?\n",
    "* What is the size of the images ?\n",
    "* What is the proportion of each observed category ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_labels.shape[0]\n",
    "n_test = test_labels.shape[0]\n",
    "\n",
    "print (\"Number of training examples: {}\".format(n_train))\n",
    "print (\"Number of testing examples: {}\".format(n_test))\n",
    "print (\"Each image is of size: {}\".format(IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, train_counts = np.unique(train_labels, return_counts=True)\n",
    "_, test_counts = np.unique(test_labels, return_counts=True)\n",
    "pd.DataFrame({'train': train_counts,\n",
    "                    'test': test_counts}, \n",
    "             index=class_names\n",
    "            ).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(train_counts,\n",
    "        explode=(0, 0, 0, 0, 0, 0) , \n",
    "        labels=class_names,\n",
    "        autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good practice: scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0 \n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "We can display a random image from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_image(class_names, images, labels):\n",
    "    \"\"\"\n",
    "        Display a random image from the images array and its correspond label from the labels array.\n",
    "    \"\"\"\n",
    "    \n",
    "    index = np.random.randint(images.shape[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(images[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_image(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display the first 25 images from the training set directly with a loop to get a better view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_examples(class_names, images, labels):\n",
    "    \"\"\"\n",
    "        Display 25 images from the images array with its corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner: Simple Model Creation\n",
    "\n",
    "Steps are:\n",
    "1. Build the model,\n",
    "1. Compile the model,\n",
    "1. Train / fit the data to the model,\n",
    "1. Evaluate the model on the testing set,\n",
    "1. Carry out an error analysis of our model.\n",
    "\n",
    "We can build an easy model composed of different layers such as:\n",
    "* Conv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\n",
    "* MaxPooling2D: The images get half sized.\n",
    "* Flatten: Transforms the format of the images from a 2d-array to a 1d-array of 150 150 3 pixel values.\n",
    "* Relu  : given a value x, returns max(x, 0).\n",
    "* Softmax: 6 neurons, probability that the image belongs to one of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can compile it with some parameters such as:\n",
    "* **Optimizer**: adam = RMSProp + Momentum.\n",
    "What is Momentum and RMSProp ?\n",
    "* Momentum = takes into account past gradient to have a better update.\n",
    "* RMSProp = exponentially weighted average of the squares of past gradients.\n",
    "* **Loss function**: we use sparse categorical crossentropy for classification, each images belongs to one class only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model to the data from the training set. The neural network will learn by itself the pattern in order to distinguish each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['acc'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_acc'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should evaluate the model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we achieve 0.76 accuracy on the testing test. We got a slight underfitting :(\n",
    "\n",
    "Let's see how the classifier is doing on random images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)     # Vector of probabilities\n",
    "pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n",
    "\n",
    "display_random_image(class_names, test_images, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "We can try to understand on which kind of images the classifier has trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n",
    "    \"\"\"\n",
    "        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n",
    "    \"\"\"\n",
    "    BOO = (test_labels == pred_labels)\n",
    "    mislabeled_indices = np.where(BOO == 0)\n",
    "    mislabeled_images = test_images[mislabeled_indices]\n",
    "    mislabeled_labels = pred_labels[mislabeled_indices]\n",
    "\n",
    "    title = \"Some examples of mislabeled images by the classifier:\"\n",
    "    display_examples(class_names,  mislabeled_images, mislabeled_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mislabeled_images(class_names, test_images, test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(test_labels, pred_labels)\n",
    "ax = plt.axes()\n",
    "sn.heatmap(CM, annot=True, \n",
    "           annot_kws={\"size\": 10}, \n",
    "           xticklabels=class_names, \n",
    "           yticklabels=class_names, ax = ax)\n",
    "ax.set_title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: The classifier has trouble with 2 kinds of images.\n",
    "It has trouble with street and buildings. Well, it can be understandable as as there are buildings in the street. \n",
    "It has also trouble with sea, glacier and moutain as well. It is hard for me to fully distinguish them.\n",
    "However, it can detects forest very accurately!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intermediate Update January 2020**\n",
    "\n",
    "* Feature extraction with VGG16 trained on ImageNet\n",
    "\n",
    "\n",
    "* Ensemble models of Neural Networks with the features extracted from VGG\n",
    "\n",
    "Inspired from: https://machinelearningmastery.com/model-averaging-ensemble-for-deep-learning-neural-networks/\n",
    "\n",
    "* Fine Tuning with VGG16 trained on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction with VGG ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract features from VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the features directly from VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the features through PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, x, y, z = train_features.shape\n",
    "n_test, x, y, z = test_features.shape\n",
    "numFeatures = x * y * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components = 2)\n",
    "\n",
    "X = train_features.reshape((n_train, x*y*z))\n",
    "pca.fit(X)\n",
    "\n",
    "C = pca.transform(X) # Repr√©sentation des individus dans les nouveaux axe\n",
    "C1 = C[:,0]\n",
    "C2 = C[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figures\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    plt.scatter(C1[train_labels == i][:1000], C2[train_labels == i][:1000], label = class_name, alpha=0.4)\n",
    "plt.legend()\n",
    "plt.title(\"PCA Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identifying clusters thanks to this PCA. The clusters correspond more or less to the labels.\n",
    "\n",
    "We see that glacier and mountain points are very close to each other, as VGG sees them as very similar.\n",
    "\n",
    "We see that there is no distinction between building and street.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on top of VGG\n",
    "\n",
    "Let's train a simple one-layer Neural Network on the features extracted from VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(train_features, train_labels, batch_size=128, epochs=15, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should get approximately 0.844 accuracy (+0.1 accuracy) over the simple ConvNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model2.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1997)\n",
    "# Number of estimators\n",
    "n_estimators = 10\n",
    "# Proporition of samples to use to train each training\n",
    "max_samples = 0.8\n",
    "\n",
    "max_samples *= n_train\n",
    "max_samples = int(max_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define n_estimators Neural Networks. \n",
    "\n",
    "Each Neural Network will be trained on random subsets of the training dataset. Each subset contains max_samples samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list()\n",
    "random = np.random.randint(50, 100, size = n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    \n",
    "    # Model\n",
    "    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape = (x, y, z)),\n",
    "                                # One layer with random size\n",
    "                                    tf.keras.layers.Dense(random[i], activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "                                ])\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Store model\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    # Train each model on a bag of the training data\n",
    "    train_idx = np.random.choice(len(train_features), size = max_samples)\n",
    "    histories.append(models[i].fit(train_features[train_idx], train_labels[train_idx], batch_size=128, epochs=10, validation_split = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregate each model individual predictions to form a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(n_estimators):\n",
    "    predictions.append(models[i].predict(test_features))\n",
    "    \n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.sum(axis = 0)\n",
    "pred_labels = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should improve our result as we have a lower variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning VGG ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-5].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Activation , MaxPooling2D, Flatten\n",
    "\n",
    "model2 = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "input_shape = model2.layers[-4].get_input_shape_at(0) # get the input shape of desired layer\n",
    "layer_input = Input(shape = (9, 9, 512)) # a new input tensor to be able to feed the desired layer\n",
    "# https://stackoverflow.com/questions/52800025/keras-give-input-to-intermediate-layer-and-get-final-output\n",
    "\n",
    "x = layer_input\n",
    "for layer in model2.layers[-4::1]:\n",
    "    x = layer(x)\n",
    "    \n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100,activation='relu')(x)\n",
    "x = Dense(6,activation='softmax')(x)\n",
    "\n",
    "# create the model\n",
    "new_model = Model(layer_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = new_model.fit(train_features, train_labels, batch_size=128, epochs=10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = new_model.predict(test_features)    \n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "print(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
